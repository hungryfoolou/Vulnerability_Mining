from scrapy import cmdline

'''
注意：
1.开全局代理运行程序（爬取外网），在服务器上运行可使用命令proxychains python entry.py使程序用代理运行
2.data\cveid文件夹中每次只放一个文件（从cveid_by_kind文件夹复制即可），
每次运行完程序后，将生成的report（在目录report_by_kind中）放在另一个文件夹中比如report_dos中
3.由于在settings.py中设置了日志，本来在控制台输出的内容保存到了log文件夹的后缀为log的日志文件中，运行完后查看log的ERROR

'''

if __name__ == "__main__":
    cmdline.execute('scrapy crawl cve_spider'.split())