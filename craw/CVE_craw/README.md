## 框架
scrapy

## 功能
通过程序cveid_craw获取所有的CVEID之后，本程序获取所有的CVEID的主流的参考链接的报告内容，并按照[漏洞类别](https://www.cvedetails.com/vulnerabilities-by-types.php)分别保存（共计13类）。


## 运行方法
1. 开启代理情况下（有的网页被墙），运行entry.py即可

```
linux：shadowsocks开启全局模式，使用命令proxychains python entry.py
win：shadowsocks开启全局模式，运行entry.py即可
```


2. 输入：

每次运行程序时先将data/cveid_by_kind中的一个文件（任意一个漏洞类别的cveid文件）拷贝到data/cveid中。


3. 输出：

（1）程序运行完成后在log文件夹中生成对应漏洞类别的一个日志文件，并在log/error_ref.txt添加错误状态码的cveid。

（2）并在report_by_kind下生成该cveid的所有参考链接的所有报告。

（3）在data/s2r_info中生成该类漏洞的报告的简要信息，主要是说明哪些cveid可能包括s2r或者eb的信息。


4. 生成某类漏洞的报告后，将report_by_kind重命名为report_漏洞类别(比如为report_dos)，新建文件report_by_kind，因为下个漏洞类别的cveid产生的报告也将存储到report_by_kind中。并将log下产生的日志文件（不是error_ref.txt，而是刚刚运行完生成的文件）添加漏洞类别的后缀。更改data/cveid中cveid文件再重复“运行方法”的第1步。



## 文件说明
log：日志文件

log/error_ref.txt ：状态码为403或404的链接

log/其他文件：data/cveid_by_kind下每个cveid文件运行产生的日志文件，说明了哪些链接没有爬取到。由于网络等原因，可能某些链接没有获取到，可以通过使用redis+本程序（本程序基于scrapy框架）提高爬取数据的完整性。


data：爬取的数据文件

data/cveid：如果想获取某类漏洞的报告，则把它的cveid文件放在该目录。

data/cveid_by_kind：所有的漏洞类别的cveid

report：暂时空

report_by_kind：所有的漏洞类别的所有报告

s2r_info：每个漏洞类别的报告的说明，说明可能存在s2r或者eb的CVEID。