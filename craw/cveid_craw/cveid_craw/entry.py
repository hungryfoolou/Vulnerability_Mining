from scrapy import cmdline
from cveid_craw.getData import get_start_url

'''
注意：
1.关闭代理运行程序，因为该https网页有相关限制（爬取http不会影响），其他比如edb就没有限制
2.如果在linux运行，需要把from cveid_craw.getData import get_start_url改为from getData import get_start_url
3.爬取得到的数据与www.cvedetails.com显示的页数不一致，比如类别httprs实际只有163个数据，对应cvedetails只有第4页有数据，
cvedetails网页写了有562页，但从第5页开始后面的页里面的数据为空
'''

if __name__ == "__main__":
    # 先运行get_start_url()获取start_urls
    # get_start_url()
    cmdline.execute('scrapy crawl cveid_spider'.split())

