# -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html

import os


class CveidCrawPipeline(object):
    def process_item(self, item, spider):  # item为cveid_spider.py的 yield的cveid_item
        cveid_path = os.getcwd() + '/data/cveid_by_kind/'  # 存放cveid的文件夹
        cve_kind = item['kind']
        cveid_dir = 'cveid_' + cve_kind + '.txt'
        cveid_file_path = os.path.join('%s\%s' % (cveid_path, cveid_dir))

        # 可能txt中已经存在某cveid
        cveid_exists_flag = 0
        if os.path.isfile(cveid_file_path):  # 存在文件才可能在文件中已经存储了某cveid
            for cveid in item['id']:
                with open(cveid_file_path, 'r', encoding='utf-8') as cveid_f:
                    if cveid_f.read().find(cveid) >= 0:  # 可能txt中已经存在该信息
                        cveid_exists_flag = 1
                        break
        if cveid_exists_flag == 0:
            for cveid in item['id']:
                with open(cveid_file_path, 'a', encoding='utf-8') as cveid_f:  # 用a而非w，用于追加
                    cveid_f.write(cveid + '\n')  # 记录CVEID

        return item
